# Adding support for --log-level and concurrent S3 get

**saurabh-hirani** commented *Apr 4, 2020*

This PR adds the following features:

1. Support for --log-level flag on command line to control the logging.

**Demo**

```
go run main.go aws --resource-type s3 --log-level debug
```

or 

```
LOG_LEVEL=debug go run main.go aws --resource-type s3
```

Valid log types are mentioned in the corresponding readme change. 


2. Optimizing the `s3.getAllS3Buckets` function to get S3 bucket properties (region,tags) concurrently as opposed to getting for each one - this was added because running S3 bucket deletion for an account > 50 buckets was too slow and was taking around 1 sec per bucket to get its properties - which would lead to linear increase as per the number of buckets. 

`s3.getAllS3Buckets` now supports batchSize which is as per `aws.MaxConcurrentGetSize` in `s3_types.go` to get X buckets data concurrently (default value: 100)

**Demo**:

1. Before adding concurrent gets:

```
go run main.go aws --resource-type s3

INFO[2020-04-04T21:10:19+05:30] The following resources types will be nuked:
INFO[2020-04-04T21:10:19+05:30] - s3
INFO[2020-04-04T21:10:21+05:30] Retrieving active AWS resources in [eu-north-1, ap-south-1, eu-west-3, eu-west-2, eu-west-1, ap-northeast-2, ap-northeast-1, sa-east-1, ca-central-1, ap-southeast-1, ap-southeast-2, eu-central-1, us-east-1, us-east-2, us-west-1, us-west-2]
INFO[2020-04-04T21:10:21+05:30] Checking region [1/16]: eu-north-1
DEBU[2020-04-04T21:10:23+05:30] Checking - Bucket bucket-1
DEBU[2020-04-04T21:10:26+05:30] Checking - Bucket bucket-2
DEBU[2020-04-04T21:10:33+05:30] Checking - Bucket bucket-3
DEBU[2020-04-04T21:10:39+05:30] Checking - Bucket bucket-4
```

The "Checking -" log - gets bucket region, checks for valid tags and decides if the bucket should be deleted or not. This serial check slows down for accounts having large number of buckets i.e at least n seconds for n buckets.

2. After adding concurrent gets:

```
go run main.go aws --resource-type s3 --log-level debug
INFO[2020-04-04T21:13:50+05:30] The following resources types will be nuked:
INFO[2020-04-04T21:13:50+05:30] - s3
INFO[2020-04-04T21:13:52+05:30] Retrieving active AWS resources in [eu-north-1, ap-south-1, eu-west-3, eu-west-2, eu-west-1, ap-northeast-2, ap-northeast-1, sa-east-1, ca-central-1, ap-southeast-1, ap-southeast-2, eu-central-1, us-east-1, us-east-2, us-west-1, us-west-2]
INFO[2020-04-04T21:13:52+05:30] Checking region [1/16]: eu-north-1
DEBU[2020-04-04T21:13:57+05:30] S3 - creating session - region eu-north-1
DEBU[2020-04-04T21:13:57+05:30] S3 - creating session - region ap-south-1
DEBU[2020-04-04T21:13:57+05:30] S3 - creating session - region eu-west-3
DEBU[2020-04-04T21:13:57+05:30] S3 - creating session - region eu-west-2
DEBU[2020-04-04T21:13:57+05:30] S3 - creating session - region eu-west-1
DEBU[2020-04-04T21:13:57+05:30] S3 - creating session - region ap-northeast-2
DEBU[2020-04-04T21:13:57+05:30] S3 - creating session - region ap-northeast-1
.
.
.
INFO[2020-04-04T21:13:57+05:30] Getting - 1-88 buckets of batch 1/1
```

This run creates S3 bucket sessions in advance (required as each bucket needs its region's session object and we have to create them per region sessions in advance to avoid creating them multiple times).

The log **Getting 1-88 buckets of batch 1/1** gets 88 buckets data in parallel subject to limit imposed by `MaxConcurrentGetSize` in `s3_types.go` and completes in 5-8 seconds as opposed to minimum of 88 seconds for 88 buckets when get operation is serial. 

 
<br />
***


**saurabh-hirani** commented *Apr 12, 2020*

@brikis98 - thanks for the feedback - updated and replied to comments. Let me know if it looks good - will squash the commits. 
***

**brikis98** commented *Apr 14, 2020*

Tests passed! Merging now.
***

**brikis98** commented *Apr 14, 2020*

https://github.com/gruntwork-io/cloud-nuke/releases/tag/v0.1.18
***

**saurabh-hirani** commented *Apr 14, 2020*

Thanks @brikis98 for the feedback and code review! 
***

