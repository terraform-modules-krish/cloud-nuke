# Feature/dynamodb nuke

**DMEvanCT** commented *Jan 4, 2021*


<br />
***


**DMEvanCT** commented *Jan 4, 2021*

This was in reference to issue #167 
***

**DMEvanCT** commented *Jan 4, 2021*

INFO[2021-01-03T23:55:54-05:00] Checking region [15/16]: us-west-1           
INFO[2021-01-03T23:55:55-05:00] Checking region [16/16]: us-west-2           
INFO[2021-01-03T23:55:55-05:00] The following 1 AWS resources will be nuked: 
INFO[2021-01-03T23:55:55-05:00] * dynamodb Table1 us-east-1
                 

THE NEXT STEPS ARE DESTRUCTIVE AND COMPLETELY IRREVERSIBLE, PROCEED WITH CAUTION!!!

Are you sure you want to nuke all listed resources? Enter 'nuke' to confirm (or exit with ^C): nuke
INFO[2021-01-03T23:55:58-05:00] Terminating 1 resources in batches           
INFO[2021-01-03T23:55:58-05:00] Deleting all EBS volumes in region us-east-1 

***

**DMEvanCT** commented *Jan 4, 2021*

@yorinasub17  This worked. Let me know if I missed documentation anywhere. 
***

**calebtote** commented *Apr 5, 2021*

Any chance of this getting reviewed soon?
***

**brikis98** commented *Apr 6, 2021*

I can re-review. Could you pull in the latest from `master` to fix the merge conflict?
***

**DMEvanCT** commented *Apr 13, 2021*

I sure can!
***

**DMEvanCT** commented *Apr 17, 2021*

@brikis98 Master has been pulled back into my branch
***

**ina-stoyanova** commented *Sep 28, 2021*

@DMEvanCT bumping this PR. Is there a way you can update with the latest from master and we can help you get this PR merged in?

***

**DMEvanCT** commented *Oct 3, 2021*

@ina-stoyanova @brikis98  I think I got all the changes you requested. Let me know if I need to update anything else.
***

**DMEvanCT** commented *Oct 6, 2021*

@ina-stoyanova @brikis98  Bumping for review
***

**ina-stoyanova** commented *Oct 7, 2021*

Thanks @DMEvanCT I'll get to review this one today!
***

**ina-stoyanova** commented *Oct 8, 2021*

I think once that's addressed (let me know if you need a hand, or example of that) we'll be good to run the tests & go ahead to merge & release.

***

**DMEvanCT** commented *Oct 8, 2021*

> Thanks for picking this one back up! @DMEvanCT! I've left a few comments, but overall it looks really good!
> 
> I think the major thing is to add pagination to the `list-tables` API call.

@ina-stoyanova The API defaults to 100 tables if not specified. We can tell the code if there are = 100 tables run the list tables again until it's under 100 then continue?
***

**DMEvanCT** commented *Oct 10, 2021*

@ina-stoyanova I fixed this and added pagination. Please check now!
***

**ina-stoyanova** commented *Oct 11, 2021*

Thanks a lot @DMEvanCT Having a look now! 

***

**DMEvanCT** commented *Oct 11, 2021*

@ina-stoyanova let me know!
***

**ina-stoyanova** commented *Oct 11, 2021*

Hey @DMEvanCT Sorry I haven't posted anything yet! I have had a look and have a few thoughts, but haven't had a chance to leave the comments just yet! I will get to that in the next few hours! This is still a priority for me today! 
***

**DMEvanCT** commented *Oct 11, 2021*

@ina-stoyanova cleaned up those recommendations also added a slice clean as the slice will need to be empty per iteration. 
***

**ina-stoyanova** commented *Oct 12, 2021*

Thanks for all the updates @DMEvanCT and the changes you've made! I just triggered the tests in a separate PR, but realised the tests probably run against this PR directly too. I'll have to wait for the `build-and-test` stage to finish. 
***

**DMEvanCT** commented *Oct 12, 2021*

@ina-stoyanova found the issue causing the test to fail. I flipped something for local testing forgot to flip it back. Can you run again?
***

**ina-stoyanova** commented *Oct 13, 2021*

Unfortunately, the tests seem to be failing still. Are you able to see the failure in CircleCI, by the way?

Here's what I'm seeing:
<img width="1260" alt="Screenshot 2021-10-13 at 13 28 10" src="https://user-images.githubusercontent.com/32835571/137132166-ce39c2f4-5b88-4bee-9247-194a0c1434fb.png">

<img width="975" alt="Screenshot 2021-10-13 at 13 32 17" src="https://user-images.githubusercontent.com/32835571/137132804-f0b02b3d-7366-43ec-a8d0-aae3bd56ef23.png">


***

**DMEvanCT** commented *Oct 13, 2021*

@ina-stoyanova  I think I fixed it! Thanks for working with me on this!!!
***

**ina-stoyanova** commented *Oct 14, 2021*

Hey @DMEvanCT thanks for the contributions so far! I've re-ran the tests and they all pass. However, the build itself is failing to generate the go binaries at the last step. I don't have too much time on my hands to look into this today, so it might be a little bit delayed. 

***

**DMEvanCT** commented *Oct 14, 2021*

It looks like the build for master was failing too?

On Thu, Oct 14, 2021 at 8:21 AM Ina Stoyanova ***@***.***>
wrote:

> Hey @DMEvanCT <https://github.com/DMEvanCT> thanks for the contributions
> so far! I've re-ran the tests and they all pass. However, the build itself
> is failing to generate the go binaries at the last step. I don't have too
> much time on my hands to look into this today, so it might be a little bit
> delayed.
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/gruntwork-io/cloud-nuke/pull/169#issuecomment-943303519>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AGLQ6ZASODTMBTJZZU6Q5OLUG3DK5ANCNFSM4VSPSYRQ>
> .
>
-- 
Evan Haston
Dark Matter IT
Deep River, CT
860-322-2034

***

**ina-stoyanova** commented *Oct 18, 2021*

Hey @DMEvanCT it doesn't actually look like master is failing for me. The problem that I see is the generation of the binaries that happens at the last step of the ci workflow. I haven't had time to dig into why this is happening yet, but hope to find some time this week! 

Thanks for the patience! My goal is to try and get this merged & released asap! 
***

**ina-stoyanova** commented *Oct 18, 2021*

Ok, so I _think_ I found the source of the failure. Raised an issue here: https://github.com/gruntwork-io/cloud-nuke/issues/220

We'll probably get to look at it still over the course of the week, hopefully sooner than later! 

***

**DMEvanCT** commented *Oct 22, 2021*

@ina-stoyanova should I pull in the latest from master to fix?

***

**ina-stoyanova** commented *Oct 26, 2021*

Hey @DMEvanCT sorry for the short silence - I was buried with other priorities last week! Yes, merging in from master should fix this. 

Just to clarify, my priority this week is back here! 

***

**DMEvanCT** commented *Oct 27, 2021*

@ina-stoyanova I have pulled master back into my branch
***

**ina-stoyanova** commented *Oct 28, 2021*

that's awesome! Running the tests now! 

***

**DMEvanCT** commented *Oct 28, 2021*

@ina-stoyanova The test failed but it's totally unrelated to my changes....
***

**DMEvanCT** commented *Oct 28, 2021*

This is master...

https://app.circleci.com/pipelines/github/gruntwork-io/cloud-nuke/5211/workflows/64ca74e4-254a-4176-8fd5-272e9fb198e5/jobs/26045
***

**ina-stoyanova** commented *Oct 28, 2021*

Hey @DMEvanCT you're right! I re-ran just to see if anything else would also fail, which was indeed the case. With @marinalimeira we're just re-testing the new functionality (it's been a few weeks) and we're going to be good to merge!
***

**DMEvanCT** commented *Oct 28, 2021*

Committed these recommendations please test.
***

**ina-stoyanova** commented *Oct 28, 2021*

Hey @DMEvanCT thanks as always for the prompt updates! We'll test it out with Marina tomorrow morning first thing! 
***

**marinalimeira** commented *Nov 2, 2021*

@brikis98 do you want to take another look before we merge?
***

**infraredgirl** commented *Nov 5, 2021*

https://github.com/gruntwork-io/cloud-nuke/releases/tag/v0.5.2
***

